{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405a318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\varshil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas\n",
    "\n",
    "# for tokenizers and reading pdf\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Display the variable in Markdown format\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# for api\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# to calculate similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a880d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def search(query, embeddings, chunks):\n",
    "    query_embedding = generate_embeddings([query])[0]\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)\n",
    "    best_match_index = similarities.argsort()[0,::-1]\n",
    "    return \"\\n\".join([chunks[best_match_index[x]] for x in range(5)])\n",
    "\n",
    "def chunk_text(text, chunk_size=1000):\n",
    "    chunk = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        new_chunk = text[i : i + chunk_size].lower()\n",
    "        chunk.append(new_chunk)\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def generate_embeddings(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors = 'pt', truncation = True, padding = True)\n",
    "        #print(\"inputs : \", inputs)\n",
    "        \"\"\"\n",
    "        The tokenizer processes the text chunk and converts it into a format suitable for the model.\n",
    "        # args...\n",
    "        \n",
    "        return_tensors='pt': This argument specifies that the output should be in PyTorch tensor format, which is required for the model.\n",
    "        truncation=True: This ensures that any input longer than the model's maximum length is truncated, preventing errors during processing.\n",
    "        padding=True: This ensures that shorter inputs are padded to the same length, allowing for batch processing.\n",
    "        \n",
    "        # keys that are returned and which will be used as arg to model:\n",
    "        input_ids : list of token ids of all tokenised words\n",
    "        attention_mask : binary mask indicating which tokes are to be attended by the model\n",
    "        token_type_ids :  It indicates which tokens belong to which segment, if all tokens belong to a single segment then [0,0,0,0]\n",
    "        overflowing_tokens : This key contains any tokens that were truncated when the input exceeded the maximum length allowed by the model. \n",
    "        num_truncated_tokens : number of truncated tokesm\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \"\"\"\n",
    "            No Gradient Calculation: The with torch.no_grad(): context manager is used to disable gradient calculations. This is important during inference to save memory and speed up computations since we don't need gradients for backpropagation.\n",
    "            Model Output: The model processes the tokenized inputs and returns the outputs, which include various hidden states. The **inputs syntax unpacks the dictionary of input tensors into keyword arguments for the model.\n",
    "            \"\"\"\n",
    "            k = outputs.last_hidden_state\n",
    "            #print(\"meaned last hidden layer : \", k.shape) # prints mean of all multidimensional layers\n",
    "            embeddings.append(k.mean(dim=1).squeeze().numpy())\n",
    "            # last hidden state is output of last layer \n",
    "            \"\"\"\n",
    "            Extracting Last Hidden State:\n",
    "            outputs.last_hidden_state contains the hidden states for all tokens in the input sequence. This is a tensor of shape (batch_size, sequence_length, hidden_size).\n",
    "            Mean Calculation:\n",
    "            mean(dim=1) computes the mean of the hidden states across all tokens in the sequence, effectively creating a single embedding for the entire input chunk. This is done to obtain a fixed-size vector representation for each chunk.\n",
    "            Squeeze and Convert to NumPy:\n",
    "            \"\"\"\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5c12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text(r\"E:\\1My_Books\\Self Help\\Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_Final.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07e6631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T H E  A L M A N A C K  O F  N A V A L  R A V I K A N T\\nE R I C  J O RG E N S O N\\nT H E  A L M A N AC K  O F  N AVA L  R AV I K A N T\\nCopyright © 2020 Eric Jorgenson\\nAll rights reserved.\\nThe Almanack of Naval Ravikant\\nA Guide to Wealth and Happiness\\nISBN\\t 978-1-5445-1422-2\\t Hardcover\\n\\t\\n978-1-5445-1421-5\\t Paperback\\n\\t\\n978-1-5445-1420-8\\t Ebook\\nThis book has been created as a public service. It is available for \\nfree download in pdf and e-reader versions on Navalmanack.com. \\nNaval is not earning any money on this book. Naval has essays, \\npodcasts and more at Nav.al and is on Twitter @Naval.\\nF O R  M Y  P A R E N T S ,  W H O  G A V E  M E \\nE V E R Y T H I N G  A N D  A L W AY S  S E E M  T O \\nF I N D  A  W AY  T O  G I V E  M O R E .\\nCONTENTS\\nIMPORTANT NOTES ON THIS BOOK (DISCLAIMER)\\t\\n9\\nFOREWORD\\t\\n13\\nERIC’S NOTE (ABOUT THIS BOOK)\\t\\n17\\nTIMELINE OF NAVAL RAVIKANT\\t\\n21\\nNOW, HERE IS NAVAL IN HIS OWN WORDS…\\t\\n23\\nPART I: WEALTH\\nBUILDING WEALTH\\t\\n29\\nUnderstand How Wealth Is Created\\t\\n30\\nFind and Build Specific Knowledge\\t\\n40\\nPlay Long-Term Games with Long-Term People\\t\\n46\\nTake on Accountability\\t\\n50\\nBuild or Buy Equity in a Business\\t\\n53\\nFind a Position of Leverage\\t\\n55\\nGet Paid for Your Judgment\\t\\n67\\nPrioritize and Focus\\t\\n69\\nFind Work That Feels Like Play\\t\\n76\\nHow to Get Lucky\\t\\n82\\nBe Patient\\t\\n87\\nBUILDING JUDGMENT\\t\\n93\\nJudgment\\t\\n94\\nHow to Think Clearly\\t\\n95\\nShed Your Identity to See Reality\\t\\n101\\nLearn the Skills of Decision-Making\\t\\n103\\nCollect Mental Models\\t\\n106\\nLearn to Love to Read\\t\\n1\\n14\\nPART II: HAPPINESS\\nLEARNING HAPPINESS\\t\\n127\\nHappiness Is Learned\\t\\n128\\nHappiness Is a Choice\\t\\n133\\nHappiness Requires Presence\\t\\n134\\nHappiness Requires Peace\\t\\n135\\nEvery Desire Is a Chosen Unhappiness\\t\\n137\\nSuccess Does Not Earn Happiness\\t\\n139\\nEnvy Is the Enemy of Happiness\\t\\n143\\nHappiness Is Built by Habits\\t\\n145\\nFind Happiness in Acceptance\\t\\n151\\nSAVING YOURSELF\\t\\n157\\nChoosing to Be Yourself\\t\\n158\\nChoosing to Care for Yourself\\t\\n161\\nMeditation + Mental Strength\\t\\n168\\nChoosing to Build Yourself\\t\\n178\\nChoosing to Grow Y'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f33bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked = chunk_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bcb8ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t h e  a l m a n a c k  o f  n a v a l  r a v i k a n t\\ne r i c  j o rg e n s o n\\nt h e  a l m a n ac k  o f  n ava l  r av i k a n t\\ncopyright © 2020 eric jorgenson\\nall rights reserved.\\nthe almanack of naval ravikant\\na guide to wealth and happiness\\nisbn\\t 978-1-5445-1422-2\\t hardcover\\n\\t\\n978-1-5445-1421-5\\t paperback\\n\\t\\n978-1-5445-1420-8\\t ebook\\nthis book has been created as a public service. it is available for \\nfree download in pdf and e-reader versions on navalmanack.com. \\nnaval is not earning any money on this book. naval has essays, \\npodcasts and more at nav.al and is on twitter @naval.\\nf o r  m y  p a r e n t s ,  w h o  g a v e  m e \\ne v e r y t h i n g  a n d  a l w ay s  s e e m  t o \\nf i n d  a  w ay  t o  g i v e  m o r e .\\ncontents\\nimportant notes on this book (disclaimer)\\t\\n9\\nforeword\\t\\n13\\neric’s note (about this book)\\t\\n17\\ntimeline of naval ravikant\\t\\n21\\nnow, here is naval in his own words…\\t\\n23\\npart i: wealth\\nbuilding wealth\\t\\n29\\nunderstand how wealth is created\\t\\n30\\nfind and build '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e1aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\varshil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# define tokenizer, pre trained tokenizer are used to avoid unknown tokens, also good for domain adaption where tokenizer will\n",
    "#  be used for specific application\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# define model\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb249fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embeddings(chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8358f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.20201841e-01,  1.35532305e-01, -3.07220165e-02,  3.79243419e-02,\n",
       "        7.14482460e-03,  3.56983766e-02,  1.92105188e-04, -1.19148032e-03,\n",
       "       -7.03828186e-02,  3.48695479e-02,  5.36719430e-03,  1.66381616e-02,\n",
       "        1.12470105e-01, -6.55039474e-02, -6.58925027e-02,  1.04939729e-01,\n",
       "       -6.09998479e-02,  5.09396661e-03, -5.39766513e-02,  1.92475058e-02,\n",
       "        5.26292659e-02,  5.46974391e-02, -3.76168154e-02, -3.73474769e-02,\n",
       "        2.41039600e-02, -1.65494289e-02, -3.76126245e-02, -6.05830029e-02,\n",
       "       -1.10070176e-01, -9.42764163e-05, -2.30580498e-03,  2.33674377e-01,\n",
       "        6.65388554e-02, -1.15526654e-03, -5.48575521e-02,  8.41637179e-02,\n",
       "        1.41858347e-02,  4.28008661e-02, -4.78527305e-04,  2.11325455e-02,\n",
       "       -6.34681731e-02, -6.46213070e-02,  4.39750999e-02,  4.60367203e-02,\n",
       "       -3.12809236e-02, -1.06854878e-01,  6.38612732e-02,  4.75981925e-03,\n",
       "        5.80895916e-02,  4.85234559e-02, -1.23284303e-01,  2.83941533e-02,\n",
       "       -1.37454405e-01, -6.66013211e-02,  7.55303130e-02,  1.32760555e-01,\n",
       "        3.42922024e-02, -7.48084579e-03, -2.14259457e-02, -5.88249601e-02,\n",
       "        2.66831275e-02,  1.36536375e-01, -6.37811720e-02, -4.33929898e-02,\n",
       "        2.38410428e-01, -4.76663709e-02,  7.44077787e-02,  1.81485966e-01,\n",
       "       -2.40218133e-01,  9.10643637e-02, -7.55523844e-03, -8.50644037e-02,\n",
       "       -1.34619493e-02,  5.20488918e-02, -1.02061562e-01, -4.56894301e-02,\n",
       "        2.18055993e-02, -9.81014445e-02,  2.96129398e-02, -8.73057544e-02,\n",
       "       -1.13966711e-01,  6.21550605e-02, -5.53147905e-02, -7.23930746e-02,\n",
       "       -6.64661080e-02,  9.12919641e-03, -5.93999634e-04, -7.66991451e-02,\n",
       "        1.85644001e-01, -1.40430005e-02,  5.02450243e-02, -1.24022081e-01,\n",
       "       -6.19600527e-02,  4.01424542e-02,  5.15775159e-02, -5.70467785e-02,\n",
       "       -6.99778125e-02,  4.13609706e-02, -1.77418500e-01,  1.57531187e-01,\n",
       "        1.59279540e-01,  6.81049228e-02,  4.52617463e-03, -2.19491217e-02,\n",
       "       -6.73925355e-02, -2.44418141e-02,  3.48032475e-03,  7.63398707e-02,\n",
       "       -2.93104979e-03, -9.98548344e-02, -2.28619382e-01, -2.15385053e-02,\n",
       "       -4.30495515e-02, -3.86096016e-02, -9.15522687e-03,  5.84601872e-02,\n",
       "       -1.04119807e-01, -2.11205650e-02, -1.06261810e-02,  3.82497422e-02,\n",
       "        6.91615120e-02, -3.14920098e-02, -2.94380561e-02,  8.68296325e-02,\n",
       "       -5.88423721e-02, -4.42371108e-02, -1.70572177e-02,  2.00178298e-32,\n",
       "       -7.22151846e-02, -4.26587053e-02,  8.49776044e-02,  1.02476202e-01,\n",
       "        1.53492121e-02,  4.25165659e-03,  6.64724559e-02, -1.07762188e-01,\n",
       "       -1.29793346e-01,  5.37609719e-02, -7.26893246e-02,  1.68540880e-01,\n",
       "       -9.73268077e-02,  2.32272167e-02,  4.18077037e-02, -1.46898508e-01,\n",
       "       -8.60931650e-02, -1.31308571e-01,  3.63601297e-02, -1.15722485e-01,\n",
       "        6.77577360e-03,  9.67923254e-02,  5.91592351e-03, -2.18204215e-01,\n",
       "        1.06768007e-03, -7.24503994e-02,  4.67683934e-02, -1.09556578e-01,\n",
       "        1.44777577e-02,  1.22586653e-01, -1.67238995e-01,  4.02508602e-02,\n",
       "       -1.30872158e-02, -1.86207101e-01, -7.09685013e-02, -1.29098177e-01,\n",
       "       -4.20396440e-02, -1.56164169e-01, -7.73405703e-03, -1.44437611e-01,\n",
       "       -1.22880138e-01,  3.97792421e-02,  7.17297867e-02,  1.47679552e-01,\n",
       "       -9.00507495e-02,  1.81739271e-01,  9.86522064e-02,  1.30342603e-01,\n",
       "        3.01818233e-02,  1.26368210e-01, -7.65687004e-02, -1.08513445e-01,\n",
       "       -3.52386013e-02, -1.95271432e-01, -9.36258882e-02, -8.70368257e-02,\n",
       "       -7.71456733e-02,  6.22572117e-02,  3.19772139e-02, -3.11461668e-02,\n",
       "       -4.65980079e-03, -3.82650942e-02,  6.02437221e-02,  4.29529659e-02,\n",
       "       -2.17434186e-02,  2.80242920e-01, -1.06348783e-01, -5.36147170e-02,\n",
       "        1.16181493e-01,  6.41548214e-03,  8.44933093e-03,  5.43346219e-02,\n",
       "        1.38227910e-01, -4.57500952e-04,  8.83155987e-02,  6.66310862e-02,\n",
       "        1.18636144e-02, -4.03450392e-02, -1.04223035e-01, -7.08157495e-02,\n",
       "       -1.52620062e-01,  7.33200237e-02, -4.94287759e-02,  2.54577827e-02,\n",
       "        5.15200198e-04,  2.14014966e-02,  1.43900827e-01, -2.20741391e-01,\n",
       "        1.20117106e-02,  3.19194719e-02, -4.85447273e-02, -3.84928659e-02,\n",
       "        9.81993079e-02, -1.21427096e-01, -2.76483446e-02, -1.93218593e-32,\n",
       "       -8.18700809e-03, -2.73250323e-02, -1.52307004e-01, -2.17675902e-02,\n",
       "        5.71008325e-02, -8.17558616e-02, -1.71758756e-02,  3.43756843e-03,\n",
       "       -7.15853646e-02, -1.06705971e-01, -7.20190927e-02, -5.30960597e-02,\n",
       "        3.93933617e-02,  2.05126107e-02, -1.58658382e-02, -7.07605332e-02,\n",
       "        1.58086419e-01,  5.28076999e-02, -8.46274123e-02,  4.59014960e-02,\n",
       "        5.21813296e-02,  4.72941957e-02, -5.91055839e-04,  7.18424097e-02,\n",
       "        3.79322320e-02,  6.47302866e-02,  2.20008893e-03,  4.13866937e-02,\n",
       "       -4.49795164e-02,  4.36258651e-02,  1.30553693e-01,  3.44209261e-02,\n",
       "       -1.28967896e-01,  5.64066395e-02, -6.48079813e-02, -5.05084060e-02,\n",
       "        1.53324082e-01, -4.03928719e-02, -9.33535770e-02,  9.65655446e-02,\n",
       "        6.12679571e-02, -7.44311884e-02, -1.15632061e-02,  8.63781050e-02,\n",
       "       -7.59044588e-02, -2.92599015e-03, -8.75064079e-03, -1.54545270e-02,\n",
       "        9.94912907e-02, -7.84796178e-02,  1.47244230e-01,  2.28371210e-02,\n",
       "        1.57480881e-01, -5.93998795e-03, -6.28048703e-02,  1.64385885e-02,\n",
       "        8.64953268e-04, -1.33185476e-01, -9.49933939e-03,  6.15213141e-02,\n",
       "       -1.40978945e-02,  1.53038606e-01, -1.31499380e-01,  1.57351300e-01,\n",
       "        4.12764028e-02, -1.18242256e-01,  9.21385959e-02,  3.22941802e-02,\n",
       "       -7.42853060e-02, -4.27842513e-03, -1.24172248e-01, -1.15587845e-01,\n",
       "       -5.61942980e-02, -1.28177896e-01, -3.80430147e-02,  7.88376480e-02,\n",
       "       -3.05453930e-02,  4.76466604e-02, -9.10593495e-02,  1.38353379e-02,\n",
       "        1.24305328e-02, -5.82069829e-02,  2.63140295e-02, -3.26419361e-02,\n",
       "       -1.09426714e-01,  1.88605115e-02,  6.03737682e-02,  1.71620306e-02,\n",
       "        5.45366900e-03, -1.56700634e-03,  1.57040618e-02, -1.05927624e-01,\n",
       "       -6.48987442e-02,  8.20868015e-02,  9.38478708e-02, -1.00736905e-07,\n",
       "       -4.52097990e-02, -5.44772968e-02, -1.00750197e-02,  4.78444472e-02,\n",
       "       -5.64507432e-02, -1.08808773e-02,  1.35922432e-01,  1.34743564e-02,\n",
       "       -1.50688679e-03,  1.17841408e-01,  3.66824791e-02,  5.08726686e-02,\n",
       "       -1.15773156e-02,  1.03164732e-01, -4.53594215e-02, -1.45158581e-02,\n",
       "        1.41279653e-01, -7.04596341e-02, -8.08341131e-02, -1.26774773e-01,\n",
       "        2.78939068e-01, -8.76164138e-02,  1.27791598e-01, -1.03151411e-01,\n",
       "       -1.30619153e-01,  5.90029210e-02, -9.91038457e-02, -1.89715717e-02,\n",
       "        1.16562732e-01,  1.13436073e-01,  1.03250474e-01,  3.02036982e-02,\n",
       "       -8.22596028e-02, -3.57566439e-02,  1.62527021e-02,  7.92245492e-02,\n",
       "        7.21896708e-04,  1.22067053e-02, -5.32200336e-02,  7.14036897e-02,\n",
       "       -7.01217055e-02,  1.06219009e-01,  5.88926002e-02,  7.30472207e-02,\n",
       "        1.71263248e-01,  7.27161253e-03, -5.62957041e-02,  8.17055330e-02,\n",
       "        1.27449647e-01, -2.32337013e-01,  1.13268889e-01,  5.04822433e-02,\n",
       "        1.08331844e-01, -3.44647169e-02,  1.11951202e-01, -2.12849546e-02,\n",
       "       -4.87277284e-02,  9.64985341e-02, -8.23650286e-02, -3.41419838e-02,\n",
       "        1.70244262e-01, -7.16567189e-02, -6.21949360e-02,  3.07738762e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac77b6",
   "metadata": {},
   "source": [
    "#### \"Embedding are values generated for each word and the values also depend on the data that was fed, it trains a NN to create weights *or* for this specific purpose called embeddings.\"\n",
    "#### So embeddings should be made context specific for specific use cases.\n",
    "#### The embeddings generated by the model are designed to capture semantic relationships:\n",
    "#### Similar texts will have embeddings that are close together in the vector space.\n",
    "#### Dissimilar texts will have embeddings that are farther apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29be38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f786d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How does naval defines good investment oppertunities?\".lower()\n",
    "\n",
    "\n",
    "rag_query = \" \".join([x for x in query.split() if x not in ['author', 'naval', 'ravikant']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c37a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_response = search(rag_query, embeddings, chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b46e5661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turn on investment = “buy-and-hold” + valuation + \\nmargin of safety\\xa0[72]\\n224\\u2002 · \\u2002 t h e  a l m a n a c k  o f  n a v a l  r a v i k a n t\\nnaval’s rules (2016)\\n\\t\\n→be present above all else.\\n\\t\\n→desire is suffering. (buddha)\\n\\t\\n→anger is a hot coal you hold in your hand while waiting to \\nthrow it at someone else. (buddha)\\n\\t\\n→if you can’t see yourself working with someone for life, \\ndon’t work with them for a day.\\n\\t\\n→reading (learning) is the ultimate meta-skill and can be \\ntraded for anything else.\\n\\t\\n→all the real benefits in life come from compound interest.\\n\\t\\n→earn with your mind, not your time.\\n\\t\\n→99 percent of all effort is wasted.\\n\\t\\n→total honesty at all times. it’s almost always possible to be \\nhonest and positive.\\n\\t\\n→praise specifically, criticize generally. (warren buffett)\\n\\t\\n→truth is that which has predictive power.\\n\\t\\n→watch every thought. (ask “why am i having this thought?”)\\n\\t\\n→all greatness comes from suffering.\\n\\t\\n→love is given, not received.\\n\\t\\n→enlightenment is the space bet\\n t h e  a l m a n a c k  o f  n a v a l  r a v i k a n t\\nyou do need to be deep in something because otherwise you’ll \\nbe a mile wide and an inch deep and you won’t get what you \\nwant out of life. you can only achieve mastery in one or two \\nthings. it’s usually things you’re obsessed about.\\xa0[74]\\nall the \\nreturns in \\nlife, whether \\nin wealth, relationships, \\nor knowledge, come from compound interest.\\nplay long-term games.\\nplay long-term games with long-term people\\nyou said, “all the returns in life, whether in wealth, relation-\\nships, or knowledge, come from compound interest.” how \\ndoes one know if they’re earning compound interest?\\nb u i l d i n g  w e a l t h \\u2002 · \\u2002 47\\ncompound interest is a very powerful concept. compound \\ninterest applies to more than just compounding capital. com-\\npounding capital is just the beginning.\\ncompounding in business relationships is very important. \\nlook at some of the top roles in society, like why someone is \\na ceo of a public company or managing billi\\nis also an angel investor, betting early on companies like \\nuber, twitter, postmates, and hundreds more.\\nmore than a financial success, naval has been sharing his own \\nphilosophy of life and happiness, attracting readers and listen-\\ners throughout the world. naval is broadly followed because he \\nis a rare combination of successful and happy. after a lifetime \\nof study and application of philosophy, economics, and wealth \\ncreation, he has proven the impact of his principles.\\ntoday, naval continues to build and invest in companies almost \\ncasually, in his own artistic way, while maintaining a healthy, \\npeaceful, and balanced life. this book collects and organizes \\n18\\u2002 · \\u2002 t h e  a l m a n a c k  o f  n a v a l  r a v i k a n t\\nthe pieces of wisdom he has shared and shows you how to \\nachieve the same for yourself.\\nnaval’s life story is instructive. an introspective founder, \\nself-taught investor, capitalist, and engineer certainly has \\nsomething to teach us all.\\nas a first-principles thin\\nable to invest in for the rest of your life and \\nhas meaning to you—go all-in and forget about the rest.\\xa0[10]\\n50\\u2002 · \\u2002 t h e  a l m a n a c k  o f  n a v a l  r a v i k a n t\\nintentions don’t matter.\\nactions do.\\ntake on accountability\\nembrace accountability and take business risks under your \\nown name. society will reward you with responsibility, equity, \\nand leverage.\\nto get rich, you need leverage. leverage comes in labor, comes \\nin capital, or it can come through code or media. but most of \\nthese, like labor and capital, people have to give to you. for \\nlabor, somebody has to follow you. for capital, somebody has \\nto give you money, assets to manage, or machines.\\nso to get these things, you have to build credibility, and you \\nhave to do it under your own name as much as possible, which \\nis risky. so, accountability is a double-edged thing. it allows \\nb u i l d i n g  w e a l t h \\u2002 · \\u2002 51\\nyou to take credit when things go well and to bear the brunt \\nof the failure when things go badly\\n company.\\nthen, you may end up with a trulia, redfin, or zillow company, \\nand then the upside could potentially be in the billions of dol-\\nlars, or the hundreds of millions of dollars.\\xa0[78]\\neach level has increasing leverage, increasing accountability, \\nincreasingly specific knowledge. you’re adding in money-\\nbased leverage on top of labor-based leverage. adding in \\ncode-based leverage on top of money and labor allows you to \\nactually create something bigger and bigger and get closer and \\ncloser to owning all the upside, not just being paid a salary.\\nyou start as a salaried employee. but you want to work your way \\nup to try and get higher leverage, more accountability, and spe-\\ncific knowledge. the combination of those over a long period \\nof time with the magic of compound interest will make you \\nwealthy.\\xa0[74]\\nthe one thing you have to avoid is the risk of ruin.\\navoiding ruin means stay out of jail. so, don’t do anything ille-\\nb u i l d i n g  w e a l t h \\u2002 · \\u2002 67\\ngal. it’s never worth'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd1883d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'content': {'parts': [{'text': 'The provided text does not directly state how Naval Ravikant defines good investment opportunities. However, it does mention several key principles that likely inform his investment approach:\\n\\n* **\"Buy-and-hold\" + valuation + margin of safety:** This suggests that Naval seeks investments with a long-term perspective, focusing on intrinsic value and a safety buffer to protect against potential losses.\\n* **Compound interest:** He emphasizes the importance of compounding returns over time, indicating a preference for investments that can generate consistent, long-term growth.\\n* **Leverage:** Naval believes in leveraging one\\'s skills and resources to maximize returns, which could translate to investing in businesses with high growth potential or opportunities for scaling.\\n* **Avoiding ruin:** He stresses the importance of protecting one\\'s capital and avoiding risky investments that could lead to significant losses.\\n\\nBased on these principles, it can be inferred that Naval likely defines good investment opportunities as those that:\\n\\n* Offer a solid foundation of intrinsic value and a margin of safety.\\n* Have the potential for long-term compounding returns.\\n* Allow for leveraging skills and resources to maximize growth.\\n* Avoid undue risk and the potential for catastrophic losses. \\n'}],\n",
       "    'role': 'model'},\n",
       "   'finishReason': 'STOP',\n",
       "   'index': 0,\n",
       "   'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
       "     'probability': 'NEGLIGIBLE'},\n",
       "    {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'},\n",
       "    {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'},\n",
       "    {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
       "     'probability': 'NEGLIGIBLE'}]}],\n",
       " 'usageMetadata': {'promptTokenCount': 1442,\n",
       "  'candidatesTokenCount': 242,\n",
       "  'totalTokenCount': 1684}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={api}'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\n",
    "                        \"text\": f\"\"\"Query: {query}\n",
    "Reference Information:\n",
    "{rag_response}\n",
    "Please generate a response based on the query and the provided reference information. \n",
    "Please do not add information from yourside. Keep it pointed on query\"\"\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"generationConfig\": {\n",
    "            \"temperature\": 0.7,\n",
    "            \"topK\": 40,\n",
    "            \"topP\": 0.95,\n",
    "            \"maxOutputTokens\": 1024,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "r = response.json()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "827165c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided text does not directly state how Naval Ravikant defines good investment opportunities. However, it does mention several key principles that likely inform his investment approach:\n",
       "\n",
       "* **\"Buy-and-hold\" + valuation + margin of safety:** This suggests that Naval seeks investments with a long-term perspective, focusing on intrinsic value and a safety buffer to protect against potential losses.\n",
       "* **Compound interest:** He emphasizes the importance of compounding returns over time, indicating a preference for investments that can generate consistent, long-term growth.\n",
       "* **Leverage:** Naval believes in leveraging one's skills and resources to maximize returns, which could translate to investing in businesses with high growth potential or opportunities for scaling.\n",
       "* **Avoiding ruin:** He stresses the importance of protecting one's capital and avoiding risky investments that could lead to significant losses.\n",
       "\n",
       "Based on these principles, it can be inferred that Naval likely defines good investment opportunities as those that:\n",
       "\n",
       "* Offer a solid foundation of intrinsic value and a margin of safety.\n",
       "* Have the potential for long-term compounding returns.\n",
       "* Allow for leveraging skills and resources to maximize growth.\n",
       "* Avoid undue risk and the potential for catastrophic losses. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(r['candidates'][0]['content']['parts'][0]['text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
